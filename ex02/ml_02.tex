\documentclass{article}
\usepackage{ml1_homework_template}

% please submit the corresponding pdf by email to
% homework@class,brml.org, and write "homework sheet xx" in the 
% title.  No more, no less!  (Instead of xx, however,
% put the decimal number of the homework sheet.)

% Please update the following line, only change XX to the homework
% sheet number
\title{homework sheet 02}


\author{
\name{Andre Seitz}\\
\imat{03622870}\\
\email{andre.seitz@mytum.de}
\And
\name{Linda Leidig} \\
\imat{03608416}\\
\email{linda.leidig@tum.de}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

%\usepackage{xyling}
\usepackage{qtree}


\usepackage{courier}
\usepackage{listings}
\lstset{
         basicstyle=\footnotesize\ttfamily, 
         numberstyle=\tiny,          
         numbersep=5pt,             
         tabsize=2,                
         extendedchars=true,      
         breaklines=true,        
         showspaces=false,      
         showtabs=false,       
         xleftmargin=17pt,
         framexleftmargin=17pt,
         framexrightmargin=5pt,
         framexbottommargin=4pt,
         showstringspaces=false 
 }
 \lstloadlanguages{
         Python
 }


\begin{document}
\maketitle

\section{Assignment: Learning by doing}

\paragraph*{Problem 1 and 2}
$\;$ 

Python code required for the solution:

\lstinputlisting[language=python]{python/decision_tree/node.py}

\lstinputlisting[language=python]{python/decision_tree/main.py}

Results:

1. Decision tree:


%\Tree{		& \K{$x_1 \leq 4.1$} \B{dl}\B{dr}\\ 
%\K{[0,6,0]} &					& \K{$x_1 \leq 6.9$}\B{dl}\B{dr}\\
%&					\K{[2,0,4]} &					& \K{[3,0,0]}}


\Tree [.{$x_1\leq4.1$ \\ g=0.658}
	{$[0,6,0]$ \\ g=0} 
	[.{$x_1\leq6.9$ \\ g=0.6494 
		{$[2,0,4]$ \\ g=0.444} 
		{$[3,0,0]$ \\ g=0} ] ]
		
		
		
2. Classification:

[ 4.1 -0.1  2.2] belongs to class [1] with a probability of 1.0.

[ 6.1  0.4  1.3] belongs to class [2] with a probability of $\frac{2}{3}$.

\paragraph*{Problem 3 and 4}
$\;$ 

Python code required for the solution:

\lstinputlisting[language=python]{python/knn/kNN.py}

\lstinputlisting[language=python]{python/knn/main.py}

Results:

1. KNN:

[ 4.1 -0.1  2.2] belongs to class [0 1 2] with a probability of $\frac{1}{3}$.
[ 6.1  0.4  1.3] belongs to class [2] with a probability of $\frac{2}{3}$.

2. KNN Regression:

Regression for [ 4.1 -0.1  2.2] results in 0.561.

Regression for [ 6.1  0.4  1.3] results in 1.396.

\paragraph*{Problem 5}
$\;$ 

The values of the second column are much smaller than the values of the first and third column. Scaling the data could compensate this problem affecting the euclidian distance (standardization).

This problem does not arise when training a decision tree since only one feature is considered for splitting the set at a time. Therefore, only the relative differences within each column are important.

\section{Assignment: Probabilistic kNN}
\paragraph*{Problem 6}
$\;$ 

sdfd

\paragraph*{Problem 7}
$\;$ 

sdfd

\paragraph*{Problem 8}
$\;$ 

sdfd

\section{Assignment: Neighbourhood Component Analysis}

\paragraph*{Problem 9}
$\;$ 

sdfd


\end{document}
